{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuScenes Map Expansion Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Init NuScenes. Requires the dataset to be stored on disk.\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc = NuScenes(version='v1.0-trainval', \\\n",
    "                dataroot='../../../../data/', \\\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_map = NuScenesMap(dataroot='../../../../data/', \\\n",
    "                       map_name='singapore-onenorth')\n",
    "bs_map = NuScenesMap(dataroot='../../../../data/', \\\n",
    "                       map_name='boston-seaport')\n",
    "sh_map = NuScenesMap(dataroot='../../../../data/', \\\n",
    "                       map_name='singapore-hollandvillage')\n",
    "sq_map = NuScenesMap(dataroot='../../../../data/', \\\n",
    "                       map_name='singapore-queenstown')\n",
    "\n",
    "# dict mapping map name to map file\n",
    "map_files = {'singapore-onenorth': so_map,\n",
    "             'boston-seaport': bs_map,\n",
    "             'singapore-hollandvillage': sh_map,\n",
    "             'singapore-queenstown': sq_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with person token as key and other features as values\n",
    "pedestrian_details = dict()\n",
    "\n",
    "# dict with scene number as key and trajectories and map name as values\n",
    "scene_info = dict()\n",
    "\n",
    "# initializing a dict for layer names and number of points in each layer\n",
    "layer_list = so_map.layer_names\n",
    "layer_list.append(\"white_area\")\n",
    "layer_dict = dict.fromkeys(layer_list, 0)\n",
    "\n",
    "# defining the sensor to extract ego_pose from sample_data, \n",
    "# we need a sensor to get sample_data\n",
    "sensor = \"LIDAR_TOP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_scene in range(850): \n",
    "    # initialize the scene\n",
    "    my_scene = nusc.scene[n_scene]\n",
    "    # getting the map name\n",
    "    cur_map = nusc.get('log', my_scene[\"log_token\"])[\"location\"]\n",
    "    # entering the scene number and map name\n",
    "    scene_info[str(n_scene)] = {\"trajectories_x\": [], \"trajectories_y\": [],\\\n",
    "                          \"map_name\": cur_map}\n",
    "\n",
    "    # per scene person token database\n",
    "    seen_person_tokens = []\n",
    "\n",
    "    # first sample\n",
    "    first_sample_token = my_scene['first_sample_token']\n",
    "    sample = nusc.get('sample', first_sample_token)\n",
    "\n",
    "    while True:\n",
    "        for ann in sample['anns']:\n",
    "            group_name = nusc.get('sample_annotation', ann)['category_name']\n",
    "            if \"human.pedestrian\" in group_name and \\\n",
    "               nusc.get('sample_annotation', ann)['instance_token'] not in seen_person_tokens: \n",
    "\n",
    "                cur_person_token = nusc.get('sample_annotation', ann)['instance_token']\n",
    "                cur_person_instance = nusc.get(\"instance\", cur_person_token)\n",
    "                nbr_samples = cur_person_instance['nbr_annotations']\n",
    "\n",
    "                # initializing the dict with the new person token\n",
    "                pedestrian_details[cur_person_token] = {\"translation\":[], \n",
    "                                                        \"rotation\":[],\n",
    "                                                        \"velocity\":[],\n",
    "                                                        \"ego_translation\":[],\n",
    "                                                        \"ego_rotation\":[],\n",
    "                                                        \"ego_time\": [],\n",
    "                                                        \"d_curb\":[],\n",
    "                                                        \"height\":[]}\n",
    "\n",
    "                first_token = cur_person_instance['first_annotation_token']\n",
    "                current_token = first_token\n",
    "\n",
    "                for i in range(nbr_samples):\n",
    "                    current_ann = nusc.get('sample_annotation', current_token)\n",
    "                    \n",
    "                    # getting the sample corresponding to this annotation to retrieve \n",
    "                    # ego details\n",
    "                    annotation_sample = nusc.get('sample', current_ann['sample_token'])\n",
    "                    \n",
    "                    if current_ann[\"attribute_tokens\"]:\n",
    "                        current_attr = nusc.get('attribute', current_ann['attribute_tokens'][0])['name']\n",
    "                        if current_attr.split(\".\")[1] != \"sitting_lying_down\":\n",
    "                            # updating pedestrian details dict\n",
    "                            pedestrian_details[cur_person_token][\"group\"] = group_name.split(\".\")[-1]\n",
    "                            pedestrian_details[cur_person_token][\"translation\"].append(\n",
    "                                        current_ann[\"translation\"])\n",
    "                            pedestrian_details[cur_person_token][\"rotation\"].append(\n",
    "                                        current_ann[\"rotation\"])\n",
    "                            pedestrian_details[cur_person_token][\"height\"].append(\n",
    "                                        current_ann[\"size\"][2])\n",
    "                            pedestrian_details[cur_person_token][\"scene_no\"] = n_scene\n",
    "                            pedestrian_details[cur_person_token][\"map_name\"] = cur_map\n",
    "                            # only takes velocity at a particular time step\n",
    "                            pedestrian_details[cur_person_token][\"velocity\"].append(\n",
    "                                list(nusc.box_velocity(current_token)))\n",
    "                            \n",
    "                            # updating ego details\n",
    "                            lidar_data = nusc.get('sample_data', \n",
    "                                                  annotation_sample['data'][sensor])\n",
    "                            ego_token = lidar_data['ego_pose_token']\n",
    "                            ego_pose = nusc.get('ego_pose', ego_token)\n",
    "                            pedestrian_details[cur_person_token][\"ego_translation\"].append(\n",
    "                                ego_pose[\"translation\"])\n",
    "                            pedestrian_details[cur_person_token][\"ego_rotation\"].append(\n",
    "                                ego_pose[\"rotation\"])\n",
    "                            pedestrian_details[cur_person_token][\"ego_time\"].append(\n",
    "                                ego_pose[\"timestamp\"])\n",
    "                                \n",
    "                            \n",
    "                            # calculating d_curb \n",
    "                            cur_ped_x = current_ann[\"translation\"][0]\n",
    "                            cur_ped_y = current_ann[\"translation\"][1]\n",
    "                            layers_on_point_dict = map_files[cur_map].layers_on_point(\n",
    "                                                           cur_ped_x, cur_ped_y)\n",
    "                            \n",
    "                            # d_curb if he is on the walkway, else give 0\n",
    "                            if layers_on_point_dict[\"walkway\"]:\n",
    "                                # serching for road type polygon 50m around pedestrian\n",
    "                                records_patch = map_files[cur_map].get_records_in_patch(\n",
    "                                     (current_ann[\"translation\"][0]-25,\n",
    "                                     current_ann[\"translation\"][1]-25,\n",
    "                                     current_ann[\"translation\"][0]+25,\n",
    "                                     current_ann[\"translation\"][1]+25), \n",
    "                                     [\"lane\", \"road_block\", \"road_segment\"])\n",
    "                                \n",
    "                                # save the closest distance to any road polygon\n",
    "                                d_curb = np.inf\n",
    "                                for l, pol in records_patch.items():\n",
    "                                    for poli in pol:\n",
    "                                        poli_token = map_files[cur_map].get(l,poli)[\"polygon_token\"]\n",
    "                                        cur_poly = map_files[cur_map].extract_polygon(poli_token)\n",
    "                                        cur_point = Point(cur_ped_x, cur_ped_y)\n",
    "                                        d_curb = min(d_curb, cur_point.distance(cur_poly))\n",
    "                                \n",
    "                                pedestrian_details[cur_person_token][\"d_curb\"].append(\n",
    "                                        d_curb)\n",
    "                            \n",
    "                            else:\n",
    "                                # pedestrian on the road has 0 distance to curb\n",
    "                                pedestrian_details[cur_person_token][\"d_curb\"].append(0)\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "#                             # ====== updating scene info dict =======\n",
    "#                             scene_info[str(n_scene)][\"trajectories_x\"].append(\n",
    "#                                         current_ann[\"translation\"][0])\n",
    "#                             scene_info[str(n_scene)][\"trajectories_y\"].append(\n",
    "#                                         current_ann[\"translation\"][1])\n",
    "                            \n",
    "#                             # ======= updating layer dict ========\n",
    "#                             cur_layers = map_files[cur_map].layers_on_point(\n",
    "#                                 current_ann[\"translation\"][0], current_ann[\"translation\"][1])\n",
    "#                             # if no layer has any tokens\n",
    "#                             if all('' == s or s.isspace() for s in cur_layers.values()):\n",
    "#                                 layer_dict[\"white_area\"] += 1\n",
    "#                             # if any layer has at least one token\n",
    "#                             else:\n",
    "#                                 for b, v in cur_layers.items():\n",
    "#                                     if v:\n",
    "#                                         layer_dict[b] += 1\n",
    "                                        \n",
    "                    current_token = current_ann[\"next\"]\n",
    "\n",
    "\n",
    "                seen_person_tokens.append(cur_person_token)\n",
    "\n",
    "        if sample['next'] != '':\n",
    "            sample = nusc.get('sample', sample['next'])\n",
    "        else:\n",
    "            #last sample of the scene\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, val in pedestrian_details.items():\n",
    "    velocities_x = [v[0] for v in val[\"velocity\"]]\n",
    "    velocities_y = [v[1] for v in val[\"velocity\"]]\n",
    "    times = val[\"ego_time\"]\n",
    "    \n",
    "    del_vx = np.diff(velocities_x)    \n",
    "    del_vy = np.diff(velocities_y)\n",
    "    del_time = 1e-6 * (np.diff(times))\n",
    "    \n",
    "    acc_x = [dx/dt for dx,dt in zip(del_vx, del_time)]\n",
    "    acc_y = [dy/dt for dy,dt in zip(del_vy, del_time)]\n",
    "    \n",
    "    acc_x.append(acc_x[-1])\n",
    "    acc_y.append(acc_y[-1])\n",
    "        \n",
    "    pedestrian_details[k][\"acceleration_x\"] = acc_x\n",
    "    pedestrian_details[k][\"acceleration_y\"] = acc_y\n",
    "    pedestrian_details[k][\"del_time\"] = del_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ped_details = {}\n",
    "\n",
    "# extracting the ped trajs with more than 16 samples\n",
    "for k, v in pedestrian_details.items():\n",
    "    if len(v['translation']) > 15:\n",
    "        if not np.any(np.isnan(np.array(v['velocity']))):\n",
    "            cur_diffs = [round(1e-6*(t-s),1) for s, t in zip(v['ego_time'], v['ego_time'][1:])]\n",
    "            if not any(i > 0.9 for i in cur_diffs):\n",
    "                new_ped_details[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING all the dict files in details folder\n",
    "with open('details/pedestrian_details.pkl', 'wb') as handle:\n",
    "    pickle.dump(pedestrian_details, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open('details/scene_info.pkl', 'wb') as handle:\n",
    "#     pickle.dump(scene_info, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open('details/layer_dict.pkl', 'wb') as handle:\n",
    "#     pickle.dump(layer_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# saving the new ped_details dict\n",
    "with open('details/new_ped_details.pkl', 'wb') as handle:\n",
    "    pickle.dump(new_ped_details, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING the necessary files\n",
    "with open('details/scene_info.pkl', 'rb') as handle:\n",
    "    scene_info = pickle.load(handle)\n",
    "    \n",
    "with open('details/pedestrian_details.pkl', 'rb') as handle:\n",
    "    pedestrian_details = pickle.load(handle)\n",
    "    \n",
    "with open('details/new_ped_details.pkl', 'rb') as handle:\n",
    "    new_ped_details = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regions of pedestrian positions in all the scenes\n",
    "plt.figure(figsize=(24,14))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.bar(list(layer_dict.keys())[3:], layer_values[3:], align='center', edgecolor='black', linewidth=1.2)\n",
    "plt.xlabel(\"Regions of the map\")\n",
    "plt.ylabel(\"Number of pedestrian positions\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.title(\"Bar plot of number of positions of pedestrians in different layers of the map\")\n",
    "plt.savefig(\"images/pedestrians_region.png\", bbox_inches='tight', pad_inches=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all the trajectories in every scene as an image over the map\n",
    "\n",
    "#turning interactive plotting off\n",
    "plt.ioff()\n",
    "\n",
    "for n_scene in range(850):\n",
    "    # plt.style.use('dark_background')\n",
    "    ego_poses = map_files[scene_info[str(n_scene)][\"map_name\"]].render_egoposes_on_fancy_map(nusc, \\\n",
    "                    scene_tokens=[nusc.scene[n_scene]['token']], verbose=False)\n",
    "\n",
    "    plt.scatter(scene_info[str(n_scene)][\"trajectories_x\"], \n",
    "                scene_info[str(n_scene)][\"trajectories_y\"], s=20, c='r', alpha=1.0, zorder=2)\n",
    "\n",
    "    out_path = \"images/scene_trajectories/\" + str(n_scene) + \"_trajectories.png\"\n",
    "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the group name frequencies for pedestrians\n",
    "group_count = defaultdict(int)\n",
    "\n",
    "for p in pedestrian_details.keys():\n",
    "    if \"group\" in pedestrian_details[p]:\n",
    "        group_count[pedestrian_details[p][\"group\"]] += 1\n",
    "    \n",
    "plt.figure(figsize=(24,14))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.bar(range(len(group_count)), list(group_count.values()), align='center')\n",
    "plt.xticks(range(len(group_count)), list(group_count.keys()))\n",
    "plt.xlabel(\"Group name\")\n",
    "plt.ylabel(\"number of pedestrians\")\n",
    "plt.title(\"Group distribution of pedestrians\")\n",
    "plt.savefig(\"images/pedestrians_group.png\", bbox_inches='tight', pad_inches=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for k in new_ped_details.keys():\n",
    "    len_list.append(len(new_ped_details[k]['translation']))\n",
    "    \n",
    "print(\"At least 16 points: \", sum(i >= 16 for i in len_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_difs = []\n",
    "\n",
    "for k, v in new_ped_details.items():\n",
    "    time_difs += [round(1e-6*(t-s),1) for s, t in zip(v['ego_time'], v['ego_time'][1:])]\n",
    "    \n",
    "values, counts = np.unique(time_difs, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(16,18))\n",
    "plt.bar(values,counts, width=0.1)\n",
    "plt.xticks(values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrian_key = list(new_ped_details.keys())[5]\n",
    "ped_scene = new_ped_details[pedestrian_key]['scene_no']\n",
    "ego_poses = map_files[scene_info[str(ped_scene)][\"map_name\"]].render_egoposes_on_fancy_map(nusc, \\\n",
    "                scene_tokens=[nusc.scene[ped_scene]['token']], verbose=False,\n",
    "                render_egoposes=False, render_egoposes_range=False, \n",
    "                render_legend=False)\n",
    "plt.scatter(np.array(new_ped_details[pedestrian_key]['ego_translation'])[:6,0], \n",
    "            np.array(new_ped_details[pedestrian_key]['ego_translation'])[:6,1], s=20, c='k', alpha=1.0, zorder=2)\n",
    "plt.scatter(np.array(new_ped_details[pedestrian_key][\"translation\"])[:6,0], \n",
    "            np.array(new_ped_details[pedestrian_key][\"translation\"])[:6,1], s=20, c='r', alpha=1.0, zorder=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_scene in range(162,163):\n",
    "    ego_poses = map_files[scene_info[str(n_scene)][\"map_name\"]].render_egoposes_on_fancy_map(\n",
    "                    nusc, scene_tokens=[nusc.scene[n_scene]['token']], verbose=False,\n",
    "                    render_egoposes=True, render_egoposes_range=False, \n",
    "                    render_legend=False)\n",
    "\n",
    "    plt.scatter(scene_info[str(n_scene)][\"trajectories_x\"], \n",
    "                scene_info[str(n_scene)][\"trajectories_y\"], s=20, c='r', alpha=1.0, zorder=2)\n",
    "\n",
    "    out_path = \"images/\" + \"new\" + \"_trajectories1.png\"\n",
    "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "dist_list = []\n",
    "\n",
    "for ped_key in new_ped_details.keys():\n",
    "    for p, v in zip(new_ped_details[ped_key][\"translation\"], \n",
    "                    new_ped_details[ped_key][\"ego_translation\"]):\n",
    "        dist_list.append(calculate_dist(p[:2], v[:2]))\n",
    "        \n",
    "plt.figure(figsize=(24,14))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.hist(dist_list, bins=10, density=True, align=\"mid\", edgecolor='black', linewidth=1.2)\n",
    "plt.xlabel(\"Distance in (m)\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "plt.title(\"Histogram of distances between pedestrian and ego-vehicle in dataset\")\n",
    "plt.savefig(\"images/pedestrians_distance.png\", bbox_inches='tight', pad_inches=1)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = velocities[~np.isnan(velocities).any(axis=1)]\n",
    "velocities = velocities[~np.all(velocities == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = np.absolute(velocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_x, vel_y, vel_z = np.mean(velocities, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average velocity in x direction \", vel_x)\n",
    "print(\"Average velocity in y direction \", vel_y)\n",
    "print(\"Average velocity in z direction \", vel_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histogram of velocity_z diff\n",
    "velz = []\n",
    "velz_diffs = []\n",
    "\n",
    "posz = []\n",
    "posz_diffs = []\n",
    "\n",
    "accx = []\n",
    "accx_diffs = []\n",
    "\n",
    "accy = []\n",
    "accy_diffs = []\n",
    "\n",
    "\n",
    "for l,z in new_ped_details.items():\n",
    "    for i in np.array(z[\"velocity\"])[:,2]:\n",
    "        velz.append(i)\n",
    "    for t in np.array(z[\"translation\"])[:,2]:\n",
    "        posz.append(t)\n",
    "    for ax in np.array(z[\"acceleration_x\"]):\n",
    "        accx.append(ax)\n",
    "    for ay in np.array(z[\"acceleration_y\"]):\n",
    "        accy.append(ay)\n",
    "    \n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.hist(velz, bins=20)\n",
    "plt.title(\"Histogram of vel_z values\")\n",
    "plt.savefig(\"images/velz.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "velz_diffs = np.diff(velz)\n",
    "plt.hist(velz_diffs, bins=20)\n",
    "plt.title(\"Histogram of vel_z difference\")\n",
    "plt.savefig(\"images/velz_diff.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.hist(accx, bins=20)\n",
    "plt.title(\"Histogram of accx values\")\n",
    "plt.savefig(\"images/accx.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "accx_diffs = np.diff(accx)\n",
    "plt.hist(accx_diffs, bins=20)\n",
    "plt.title(\"Histogram of accx difference\")\n",
    "plt.savefig(\"images/accx_diff.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.hist(accy, bins=20)\n",
    "plt.title(\"Histogram of accy values\")\n",
    "plt.savefig(\"images/accy.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "accy_diffs = np.diff(accy)\n",
    "plt.hist(accy_diffs, bins=20)\n",
    "plt.title(\"Histogram of accy difference\")\n",
    "plt.savefig(\"images/accy_diff.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group height analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse the heights of different groups\n",
    "\n",
    "adult_heights = []\n",
    "child_heights = []\n",
    "personal_mobility_heights = []\n",
    "other_groups = set()\n",
    "\n",
    "for k, val in new_ped_details.items():\n",
    "    if val[\"group\"] == \"child\":\n",
    "        for h in val[\"height\"]:\n",
    "            child_heights.append(h)\n",
    "    elif val[\"group\"] == \"personal_mobility\":\n",
    "        for h in val[\"height\"]:\n",
    "            personal_mobility_heights.append(h)\n",
    "    else: \n",
    "        other_groups.add(val[\"group\"])\n",
    "        for h in val[\"height\"]:\n",
    "            adult_heights.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.hist(child_heights, bins=10)\n",
    "plt.xlabel(\"Height in m\")\n",
    "plt.ylabel(\"Number of annotations\")\n",
    "plt.title(\"Height distribution of child group\")\n",
    "plt.savefig(\"images/group_height/child.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.hist(personal_mobility_heights, bins=10)\n",
    "plt.xlabel(\"Height in m\")\n",
    "plt.ylabel(\"Number of annotations\")\n",
    "plt.title(\"Height distribution of personal_mobility group\")\n",
    "plt.savefig(\"images/group_height/personal_mobility.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.hist(adult_heights, bins=10)\n",
    "plt.xlabel(\"Height in m\")\n",
    "plt.ylabel(\"Number of annotations\")\n",
    "plt.title(\"Height distribution of adult group\")\n",
    "plt.savefig(\"images/group_height/adult.png\", bbox_inches='tight', pad_inches=1)    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nuscnenes)",
   "language": "python",
   "name": "nuscnenes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
